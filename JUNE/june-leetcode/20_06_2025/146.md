## Least Recently Used (LRU) Cache
This project implements an efficient Least Recently Used (LRU) Cache data structure. The LRU cache supports constant time get and put operations using a combination of a hashmap and a doubly linked list.

**Understand**
The LRU cache evicts the least recently used item when it exceeds its capacity. It should support:

- get(key): Returns the value of the key if it exists, otherwise returns -1.

- put(key, value): Inserts or updates the value of the key. If the cache exceeds capacity, the least recently used item is removed.

**Match**
This problem is a classic example of:

- Cache design

- Hashmap + Doubly Linked List combo

- Constant-time operations for both access and updates

- Recently-used item tracking with ordering

**Plan**
- Use a hashmap to map keys to nodes for O(1) access.

- Use a doubly linked list to maintain the order of usage.

    - The most recently used (MRU) item is at the tail (right).

    - The least recently used (LRU) item is at the head (left).

- Each time get() or put() is called, update the node to MRU position.

- When the cache exceeds capacity, remove the node just after the head.


Implement
```python
class Node():
    def __init__(self, key, val):
        self.key = key
        self.val = val
        self.next = None
        self.prev = None

class LRUCache(object):
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = {}
        self.left = Node(0, 0)
        self.right = Node(0, 0)
        self.left.next = self.right
        self.right.prev = self.left

    def remove(self, node):
        next = node.next
        prev = node.prev
        next.prev = prev
        prev.next = next

    def add(self, node):
        prev = self.right.prev
        prev.next = node
        node.prev = prev
        node.next = self.right
        self.right.prev = node

    def get(self, key):
        if key in self.cache:
            self.remove(self.cache[key])
            self.add(self.cache[key])
            return self.cache[key].val
        return -1

    def put(self, key, value):
        if key in self.cache:
            self.remove(self.cache[key])
        self.cache[key] = Node(key, value)
        self.add(self.cache[key])
        if len(self.cache) > self.capacity:
            lru = self.left.next
            self.remove(lru)
            del self.cache[lru.key]
```

**Review**
- The use of sentinel head and tail nodes simplifies edge cases.

- remove() and add() operate in O(1) time.

- The hashmap keeps lookup and insertions fast, while the doubly linked list maintains usage order.

- Clean separation of logic for readability and reusability.

**Evaluate**
- Time Complexity:

get() → O(1)

put() → O(1)

- Space Complexity: O(capacity)